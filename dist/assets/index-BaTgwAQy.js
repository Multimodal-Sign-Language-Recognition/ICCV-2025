import{a as e,g as a,r as t,j as n,m as s,A as i,R as r}from"./vendor-BfW7QmCo.js";import{X as o,M as l,C as c,a as d,H as m,E as h,b as u,A as g,c as p,F as x,U as b,d as f,R as v,P as y,e as w,L as j,T as C,f as N,g as k,h as S,i as A,j as I,k as R,l as M,S as L,D,m as E,n as P,B as U,o as z,Z as T,p as H,q as V,r as O,s as B,t as F}from"./ui-ClUhs0B0.js";!function(){const e=document.createElement("link").relList;if(!(e&&e.supports&&e.supports("modulepreload"))){for(const e of document.querySelectorAll('link[rel="modulepreload"]'))a(e);new MutationObserver((e=>{for(const t of e)if("childList"===t.type)for(const e of t.addedNodes)"LINK"===e.tagName&&"modulepreload"===e.rel&&a(e)})).observe(document,{childList:!0,subtree:!0})}function a(e){if(e.ep)return;e.ep=!0;const a=function(e){const a={};return e.integrity&&(a.integrity=e.integrity),e.referrerPolicy&&(a.referrerPolicy=e.referrerPolicy),"use-credentials"===e.crossOrigin?a.credentials="include":"anonymous"===e.crossOrigin?a.credentials="omit":a.credentials="same-origin",a}(e);fetch(e.href,a)}}();var K,G={};const $=a(function(){if(K)return G;K=1;var a=e();return G.createRoot=a.createRoot,G.hydrateRoot=a.hydrateRoot,G}()),W=t.forwardRef((({navLinks:e,activeSection:a,onNavClick:r},c)=>{const[d,m]=t.useState(!1),[h,u]=t.useState(!1);t.useEffect((()=>{const e=()=>u(window.scrollY>20);return window.addEventListener("scroll",e),()=>window.removeEventListener("scroll",e)}),[]);const g=({id:e,name:t,isMobile:i=!1})=>n.jsxs("button",{onClick:()=>{r(e),i&&m(!1)},className:`relative px-3 py-2 rounded-md text-base font-bold transition-all duration-200 ease-in-out group font-poppins\n                  ${i?"block w-full text-left text-lg py-3":""}\n                  ${a===e?i?"bg-brand-primary-light text-white":h?"text-brand-accent-light":"text-brand-primary-dark":i?"text-brand-neutral-200 hover:bg-brand-neutral-700 hover:text-white":h?"text-white hover:text-brand-accent-light":"text-brand-neutral-800 hover:text-brand-primary"}`,children:[t,!i&&a===e&&n.jsx(s.div,{className:`absolute -bottom-1 left-0 right-0 h-1 ${h?"bg-brand-accent":"bg-brand-primary-dark"} rounded-t-md`,layoutId:"activePill",initial:!1,transition:{type:"spring",stiffness:350,damping:30}})]}),p=[{id:"hero",name:"Top"},...e];return n.jsxs(s.header,{ref:c,className:"fixed top-0 left-0 right-0 z-50 transition-all duration-300 ease-out\n                  "+(h||d?"bg-brand-neutral-900/90 shadow-xl backdrop-blur-md py-3":"bg-white/80 py-4 shadow-md backdrop-blur-sm"),children:[n.jsx("div",{className:"container-core",children:n.jsxs("div",{className:"flex items-center justify-between h-12",children:[n.jsx("button",{onClick:()=>r("hero"),className:"flex items-center space-x-2 transition-opacity",children:n.jsx("img",{src:"/ICCV-2025/assets/logo-CGnXXrjY.jpeg",alt:"MSLR Logo",className:"h-10 w-30 rounded-full"})}),n.jsx("nav",{className:"hidden lg:flex space-x-1 items-center",children:e.map((e=>n.jsx(g,{id:e.id,name:e.name},e.id)))}),n.jsx("div",{className:"lg:hidden",children:n.jsx("button",{onClick:()=>m(!d),className:"p-2 rounded-md focus:outline-none "+(h?"text-white hover:text-brand-accent-light":"text-brand-neutral-800 hover:text-brand-primary"),"aria-label":"Toggle menu",children:d?n.jsx(o,{size:28}):n.jsx(l,{size:28})})})]})}),n.jsx(i,{children:d&&n.jsx(s.div,{initial:{opacity:0,height:0},animate:{opacity:1,height:"auto"},exit:{opacity:0,height:0},transition:{duration:.3,ease:"easeInOut"},className:"lg:hidden absolute top-full left-0 right-0 bg-brand-neutral-800 shadow-xl rounded-b-lg overflow-hidden",children:n.jsx("div",{className:"px-3 pt-2 pb-4 space-y-1 sm:px-4",children:p.map((e=>n.jsx(g,{id:e.id,name:e.name,isMobile:!0},e.id)))})})}),n.jsx("div",{className:`absolute bottom-0 left-0 right-0 h-0.5 ${h?"bg-gradient-to-r from-transparent via-brand-accent/50 to-transparent":"bg-gradient-to-r from-transparent via-brand-primary/50 to-transparent"} opacity-70`})]})}));W.displayName="Header";const _=({src:e,alt:a,className:s,width:i,height:r,priority:o=!1,loading:l="lazy",sizes:c="100vw"})=>{const[d,m]=t.useState(!1),[h,u]=t.useState(!1);t.useEffect((()=>{m(!1),u(!1)}),[e]);const g=o?"eager":l;return n.jsxs("div",{className:`relative overflow-hidden ${s}`,style:{width:i,height:r},children:[!d&&!h&&n.jsx("div",{className:"absolute inset-0 bg-brand-neutral-200 animate-pulse rounded-lg","aria-hidden":"true"}),h&&n.jsx("div",{className:"absolute inset-0 flex items-center justify-center bg-brand-neutral-100 rounded-lg",children:n.jsx("span",{className:"text-brand-neutral-500 text-sm",children:"Image not available"})}),n.jsx("img",{src:e,alt:a,className:`${s} ${d?"opacity-100":"opacity-0"} transition-opacity duration-300`,width:i,height:r,onLoad:()=>m(!0),onError:()=>u(!0),loading:g,sizes:c,decoding:"async"})]})};function J(e){"undefined"!=typeof window&&"undefined"!=typeof document&&e.forEach((e=>{const a=document.createElement("link");var t;a.rel="preload",a.as="image",a.href=(t=e,"undefined"==typeof window||"undefined"==typeof document?t:0===document.createElement("canvas").toDataURL("image/webp").indexOf("data:image/webp")&&(t.endsWith(".jpg")||t.endsWith(".jpeg")||t.endsWith(".png"))?t.substring(0,t.lastIndexOf("."))+".webp":t),document.head.appendChild(a)}))}const q="/ICCV-2025/assets/iccv2025-DRJUPX61.svg",Y="/ICCV-2025/assets/1__LRD9SzCgmze-8jC25O3KA-bzfY-bXm.png",X="/ICCV-2025/assets/honoluluSkyline-DI8Lzz0W.jpeg",Z=()=>{const e="1st Multimodal Sign Language Recognition Workshop";t.useEffect((()=>{J([Y,X,q])}),[]);const a={hidden:{opacity:0,y:10},visible:{opacity:1,y:0,transition:{type:"spring",stiffness:120,damping:5}}},i={hidden:{opacity:0,y:20},visible:{opacity:1,y:0,transition:{duration:.6,ease:"easeOut"}}};return n.jsxs("section",{className:"relative bg-brand-neutral-900 overflow-hidden py-14 md:py-20",children:[n.jsx("div",{className:"absolute inset-0 bg-gradient-to-r from-brand-neutral-900 via-brand-neutral-800 to-brand-neutral-900"}),n.jsx(s.div,{className:"absolute inset-0 w-full h-full overflow-hidden z-0",initial:{opacity:0,scale:1.1},animate:{opacity:.85,scale:1},transition:{duration:1.2,ease:"easeOut"},children:n.jsxs("div",{className:"relative w-full h-full",children:[n.jsx("div",{className:"absolute inset-0 bg-black/60 z-10"}),n.jsx(_,{src:X,alt:"Honolulu skyline",className:"w-full h-full object-cover object-center",width:"100%",height:"100%",priority:!0,loading:"eager",sizes:"(max-width: 768px) 100vw, 60vw"})]})}),n.jsxs("div",{className:"container-core relative mx-auto z-10",children:[n.jsx("div",{className:"grid grid-cols-1 md:grid-cols-12 gap-4 md:gap-6 items-center",children:n.jsxs(s.div,{variants:{hidden:{opacity:0,y:20},visible:{opacity:1,y:0,transition:{duration:.005,ease:"easeOut",staggerChildren:8e-4,delayChildren:3e-4}}},initial:"hidden",animate:"visible",className:"md:col-span-8 md:col-start-3 text-center px-4 md:px-6 py-4 md:py-8",children:[n.jsx(s.h1,{className:"font-oswald text-4xl sm:text-5xl md:text-6xl font-bold text-white leading-tight","aria-label":e,children:e.split(" ").map(((e,t)=>n.jsx("span",{className:"inline-block mr-4",children:e.split("").map(((e,i)=>n.jsx(s.span,{variants:a,className:"inline-block","aria-hidden":"true",children:e},`char-${t}-${i}`)))},`word-${t}`)))}),n.jsx(s.p,{className:"font-roboto text-xl sm:text-2xl md:text-3xl mt-4 mb-6 text-brand-neutral-200",variants:i,children:"IEEE/CVF ICCV 2025"}),n.jsxs(s.div,{variants:i,className:"w-fit mx-auto space-y-1 mb-6 bg-brand-neutral-800 bg-opacity-80 p-4 rounded-xl",children:[n.jsx("p",{className:"w-fit mx-auto text-base sm:text-lg font-sharetech text-brand-accent-light tracking-wider",children:"Honolulu, Hawaii, USA"}),n.jsx("p",{className:"w-fit mx-auto text-base sm:text-lg font-sharetech text-brand-accent-light tracking-wider",children:"October 20th, 2025"})]}),n.jsx(s.div,{variants:i,className:"mb-8 flex justify-center",children:n.jsx("a",{href:"https://iccv.thecvf.com/",target:"_blank",rel:"noopener noreferrer",className:"inline-block hover:opacity-80 transition-opacity","aria-label":"ICCV 2025 website",children:n.jsx("img",{src:q,alt:"ICCV 2025",className:"h-12 w-auto",width:"auto",height:"48",loading:"eager"})})}),n.jsxs(s.button,{variants:i,className:"px-6 py-3 bg-brand-primary text-white rounded-full font-medium \n                                    hover:bg-brand-primary-dark transition-all duration-300 \n                                    shadow-lg hover:shadow-brand-primary/30 hover:translate-y-[-2px]\n                                    flex items-center mx-auto","aria-label":"Register Now",children:[n.jsx("a",{href:"https://cmt3.research.microsoft.com/User/Login?ReturnUrl=%2FMSLR2025",children:"Submit Your Paper"}),n.jsx(c,{size:18,className:"ml-2 text-white","aria-hidden":"true"})]})]})}),n.jsx("div",{className:"absolute inset-0 pointer-events-none","aria-hidden":"true",children:[...Array(6)].map(((e,a)=>n.jsx(s.div,{className:"absolute left-0 overflow-hidden rounded-lg blur-sm opacity-60",style:{width:30+40*Math.random()+"px",height:30+40*Math.random()+"px",left:20*Math.random()+"%",top:10+80*Math.random()+"%"},initial:{opacity:0,x:-20},animate:{opacity:[0,.6,0],x:[-20,0,20],y:[0,-10,0]},transition:{duration:4+6*Math.random(),repeat:1/0,delay:5*Math.random()},children:n.jsx("img",{src:Y,alt:"",className:"w-full h-full object-cover",loading:"lazy"})},`left-symbol-${a}`)))})]}),n.jsxs("div",{className:"absolute bottom-0 right-0 w-full h-24 overflow-hidden z-10 opacity-30 pointer-events-none","aria-hidden":"true",children:[n.jsx("div",{className:"w-full h-full bg-gradient-to-t from-brand-neutral-900 to-transparent"}),[...Array(15)].map(((e,a)=>n.jsx(s.div,{className:"absolute w-1.5 h-1.5 rounded-full bg-white",style:{right:50*Math.random()+"%",bottom:100*Math.random()+"%"},initial:{opacity:0},animate:{opacity:[0,.7,0],y:[0,-10,-20]},transition:{duration:2+3*Math.random(),repeat:1/0,delay:5*Math.random()}},`dot-${a}`)))]})]})},Q=()=>{const e=(new Date).getFullYear();return n.jsx("footer",{className:"bg-brand-neutral-800 text-brand-neutral-300 section-padding",children:n.jsxs("div",{className:"container-core",children:[n.jsxs("div",{className:"mt-16 border-t border-white/20 pt-10",children:[n.jsx("h5",{className:"font-poppins text-2xl text-white mb-6 font-semibold text-center",children:"Sponsors"}),n.jsxs("div",{className:"flex flex-wrap justify-center items-center gap-12",children:[n.jsx("a",{href:"https://www.sharedtech.com.sa/",target:"_blank",rel:"noopener noreferrer",className:"hover:opacity-80 transition-opacity",children:n.jsx("img",{src:"/ICCV-2025/assets/SharedTech-1Xp-xWQG.png",alt:"SharedTech Logo",className:"h-20 sm:h-24 object-contain"})}),n.jsx("a",{href:"https://ri.kfupm.edu.sa/jrcai",target:"_blank",rel:"noopener noreferrer",className:"hover:opacity-80 transition-opacity",children:n.jsx("img",{src:"/ICCV-2025/assets/jrc-kfupm-logo-white-BM1gCeTy.png",alt:"JRCAI Logo",className:"h-20 sm:h-24 object-contain"})}),n.jsx("a",{href:"http://perceivelab.com/",target:"_blank",rel:"noopener noreferrer",className:"hover:opacity-80 transition-opacity",children:n.jsx("img",{src:"/ICCV-2025/assets/PeRCeiVeLab-LogoExtended-DBwDhdpd.png",alt:"PeRCeiVeLab Logo",className:"h-20 sm:h-24 object-contain"})})]})]}),n.jsxs("div",{className:"mt-12 pt-8 border-t border-brand-neutral-700 text-center text-sm",children:[n.jsxs("p",{className:"flex items-center justify-center font-poppins",children:[n.jsx(d,{size:16,className:"mr-1.5"})," ",e," MSLR Workshop. All Rights Reserved."]}),n.jsxs("p",{className:"mt-1 font-poppins",children:["Crafted with ",n.jsx(m,{size:14,className:"inline mx-1 text-red-400 fill-current"})," by",n.jsxs("a",{href:"https://www.esamjaafar.com/",target:"_blank",rel:"noopener noreferrer",className:"inline-flex items-center ml-1 text-brand-accent hover:text-brand-accent-light transition-colors group",children:["Esam Jaafar",n.jsx(h,{size:12,className:"ml-1 opacity-0 group-hover:opacity-100 transition-opacity"})]})]})]})]})})},ee=({children:e,id:a,title:i,subtitle:r,className:o="",bgColor:l="bg-brand-neutral-50",titleClassName:c="text-brand-primary-dark",contentMaxWidth:d="max-w-7xl"})=>{const[m,h]=(({threshold:e=0,rootMargin:a="0px",triggerOnce:n=!1,root:s=null,skip:i=!1}={})=>{const[r,o]=t.useState(!1),[l,c]=t.useState(null),d=t.useRef(),m=t.useRef(null);return t.useEffect((()=>{if(i)return;m.current&&m.current.disconnect(),m.current=new IntersectionObserver((([e])=>{const a=e.isIntersecting;o(a),c(e),a&&n&&d.current&&m.current.unobserve(d.current)}),{threshold:e,rootMargin:a,root:s});const t=d.current;return t&&m.current.observe(t),()=>{m.current&&t&&(m.current.unobserve(t),m.current.disconnect())}}),[e,a,n,s,i]),[d,r,l]})({triggerOnce:!0,threshold:.1,rootMargin:"0px 0px -10% 0px"}),u={hidden:{opacity:0,y:20},visible:{opacity:1,y:0,transition:{duration:.6,ease:"easeOut"}}};return n.jsx(s.section,{ref:m,className:`section-padding relative ${l} ${o} min-h-section`,variants:{hidden:{opacity:0},visible:{opacity:1,transition:{staggerChildren:.1,duration:.5,delayChildren:.2,ease:"easeOut"}}},initial:"hidden",animate:h?"visible":"hidden",style:{opacity:0},"aria-labelledby":i?`${a}-title`:void 0,children:n.jsxs("div",{className:`container-core ${d} mx-auto`,children:[(i||r)&&n.jsxs("div",{className:"mb-12 md:mb-16 text-center",children:[r&&n.jsx(s.p,{className:"text-base md:text-lg font-poppins text-brand-accent uppercase tracking-wider mb-2 font-medium",variants:u,children:r}),i&&n.jsx(s.h2,{id:`${a}-title`,className:`text-3xl sm:text-4xl lg:text-5xl font-bold ${c} font-poppins`,variants:u,children:i}),i&&n.jsx(s.div,{className:"mt-4 h-1 w-20 mx-auto "+(c.includes("white")||c.includes("light")||c.includes("brand-neutral-50"),"bg-brand-accent"),variants:{hidden:{scaleX:0},visible:{scaleX:1,transition:{duration:.7,ease:"circOut",delay:.2}}},style:{transformOrigin:"center"},"aria-hidden":"true"})]}),e]})})},ae="/ICCV-2025/assets/RichardBowden-M2AVRWAe.webp",te="/ICCV-2025/assets/oscarkoller-BxFqHVcN.jpg",ne="/ICCV-2025/assets/leon-sigal-Sad1AI0q.jpg",se="/ICCV-2025/assets/glasser_abraham_headshot_cropped-Zprv_MEm.jpeg",ie={overview:["Sign language recognition has undergone rapid transformation in the past five years, fueled by advancements in deep learning and the integration of multimodal data sources. Both vision-based and sensor-based approaches have significantly improved accuracy and generalization, with emerging techniques combining RGB video, depth, skeletal keypoints, facial landmarks, and even radar data. These advances offer greater robustness and privacy in diverse real-world applications.","Continuous Sign Language Recognition (CSLR) remains particularly challenging due to the need for precise temporal segmentation and the scarcity of annotated data. Innovative weakly-supervised, cross-lingual, and few-shot learning methods are addressing these gaps, enabling scalable solutions.","Meanwhile, the field is expanding beyond recognition into translation and production, with generative models enabling avatar-based, fluent sign language synthesis. These developments are paving the way for seamless communication between Deaf and hearing communities. Foundational work in sign language translation further reveals the complexity of multi-channel linguistic articulation, emphasizing the urgent need for new datasets, benchmarks, and evaluation metrics tailored to sign languages.","This workshop brings together researchers advancing Sign Language Recognition and Understanding, spanning isolated and continuous SLR, with focus on novel architectures, temporal modeling, and signer-independent systems. It highlights multimodal fusion—RGB, depth, skeletal data, facial expressions, and radar—for robust recognition, along with self-supervised and few-shot learning for data efficiency and domain adaptation. The program also covers sign language translation and production, including neural/statistical MT, avatar-based synthesis, and context-aware generation. Emphasis will be placed on diverse, ethically sourced datasets, cross-lingual benchmarks, privacy-preserving sensing, and real-world applications in healthcare, accessibility, and ethical AI practices."],callForPapers:{intro:"We invite high-quality full-paper submissions on topics including, but not limited to:",categories:[{title:"Sign Language Recognition & Understanding",icon:n.jsx(g,{className:"w-7 h-7 text-brand-accent"}),items:["Isolated & Continuous SLR: novel architectures, temporal modeling, signer-independent recognition.","Multimodal Fusion: RGB, depth, skeletal keypoints, facial expressions, radar for robust SLR.","Self-Supervised & Few-Shot Learning: data-efficient sign recognition, domain adaptation, zero-shot learning."]},{title:"Sign Language Translation & Production",icon:n.jsx(p,{className:"w-7 h-7 text-brand-accent"}),items:["Statistical & Neural MT for Sign Languages: end-to-end models for sign-to-text and text-to-sign translation.","Generative Models for Sign Production: avatar-based synthesis, neural rendering, context-aware generation."]},{title:"Datasets, Benchmarks & Metrics",icon:n.jsx(x,{className:"w-7 h-7 text-brand-accent"}),items:["New Corpora & Protocols: diverse, ethically sourced datasets; signer-independent and cross-lingual benchmarks.","Privacy-Preserving Sensing: radar and non-visual modalities as alternatives to camera-based systems."]},{title:"SLR Applications & Ethics",icon:n.jsx(b,{className:"w-7 h-7 text-brand-accent"}),items:["Healthcare & Accessibility: deployment of SLR systems in clinical, telemedicine, and assistive contexts.","Ethical Considerations: community-involved research, data governance, and algorithmic fairness."]}],outro:"Submissions should follow the ICCV 2025 formatting guidelines and will undergo double-blind peer review. Accepted papers will be published in the ICCV Workshop Proceedings."}},re=[{name:"Prof. Richard Bowden",affiliation:"University of Surrey, UK",imgSrc:ae,bio:"Richard Bowden is Professor of Computer Vision and Machine Learning at the University of Surrey where he leads the Cognitive Vision Group within CVSSP and is Associate Dean for postgraduate research within his faculty. His research centres on the use of computer vision to locate, track, understand and learn from humans.",link:"https://scholar.google.com/citations?user=mvvgDvcAAAAJ"},{name:"Dr. Oscar Koller",affiliation:"Microsoft Inc., USA",imgSrc:te,bio:"Oscar Koller is an applied scientist in Microsoft's Speech and Language group. His research interests span many topics across speech recognition, sign language translation, sign language production, and computer vision in general.",link:"https://scholar.google.com/citations?hl=it&user=vZrN9OgAAAAJ"},{name:"Dr. Leonid Sigal",affiliation:"University of British Columbia, Canada",imgSrc:ne,bio:"Prof. Leonid Sigal is a Professor at the University of British Columbia (UBC). He was appointed CIFAR AI Chair at the Vector Institute in 2019 and an NSERC Tier 2 Canada Research Chair in Computer Vision and Machine Learning in 2018. Prior to this, he was a Senior Research Scientist, and a group lead, at Disney Research. He completed his Ph.D at Brown University in 2008; received his B.Sc. degrees in Computer Science and Mathematics from Boston University in 1999, his M.A. from Boston University in 1999, and his M.S. from Brown University in 2003. Leonid’s research interests lie in the areas of computer vision, machine learning, and computer graphics; with the emphasis on approaches for visual and multi-modal representation learning, recognition, understanding and generative modeling. He has won a number of research awards, including Killam Accelerator Fellowship in 2021 and has published over 100 papers in venues such as CVPR, ICCV, ECCV, NeurIPS, ICLR, and Siggraph.",link:"https://scholar.google.com/citations?user=P2mG6rcAAAAJ&hl=en"},{name:"Dr. Abraham Glasser",affiliation:"Gallaudet University, USA",imgSrc:se,bio:"Dr. Abraham Glasser is a faculty member in the Accessible Human-Centered Computing program at Gallaudet University, and there he is also co-director of the Rehabilitation Engineering Research Center on Technology for the Deaf and Hard of Hearing (DHH RERC). He and his students conduct Human Computer Interaction (HCI) research involving AI, immersive technologies, and accessible computing for Deaf and Hard of Hearing users. He is also a member of the Coalition for Sign Language Equity in Technology (CoSET) and has contributed to published resources supporting standards work, e.g. for AI-based interpreting. Overall, Dr. Glasser has published numerous works and delivered award-winning presentations at prestigious international venues, such as ACM, IEEE, and other events, including but not limited to AAATE, ASSETS, CHI, CSUN ATC, CUI, CVPR, DAC, EMNLP, GALA, ICED, LREC, TAPIA, TISLR, IEEE VR, VRST, W4A, XR ACCESS, and WFD events.",link:"https://scholar.google.com/citations?hl=en&user=z1fXN4AAAAAJ"}],oe={hidden:{opacity:0,y:20},visible:{opacity:1,y:0,transition:{duration:.5,ease:"easeOut"}}},le=(e=0)=>({hidden:{opacity:0,scale:.95,y:20},visible:{opacity:1,scale:1,y:0,transition:{duration:.5,ease:"easeOut",delay:e}}}),ce={workshop:[{date:"May 12, 2025",event:"Launch of the Challenge",icon:v},{date:"July 3, 2025",event:"Workshop Paper Submission Deadline",icon:y},{date:"July 11, 2025",event:"Notification to Authors",icon:w},{date:"August 5, 2025",event:"Camera-ready Deadline",icon:j},{date:"October 20, 2025",event:"Workshop Date",icon:p,highlight:!0}],challenge:[{date:"May 12, 2025",event:"Release of training and development sets",icon:v},{date:"June 2, 2025",event:"Release of test sets",icon:C},{date:"June 23, 2025",event:"Challenge submission deadline",icon:y},{date:"June 24, 2025",event:"Announcement of results",icon:g},{date:"July 3, 2025",event:"Paper submission deadline",icon:j}]},de=(e=0)=>({hidden:{opacity:0,y:30},visible:{opacity:1,y:0,transition:{duration:.5,ease:"easeOut",delay:e}}}),me=(e=0)=>({hidden:{opacity:0,x:-20},visible:{opacity:1,x:0,transition:{duration:.4,ease:"easeOut",delay:e}}}),he=({date:e,event:a,Icon:t,highlight:i,delay:r})=>n.jsxs(s.li,{className:"relative pl-12 py-3 border-l-2 "+(i?"border-brand-accent":"border-brand-neutral-300 hover:border-brand-primary-light transition-colors"),variants:me(r),children:[n.jsx("div",{className:"absolute -left-4 top-1/2 -translate-y-1/2 w-8 h-8 rounded-full flex items-center justify-center shadow-md "+(i?"bg-brand-accent text-white":"bg-brand-primary text-white"),children:n.jsx(t,{size:18})}),n.jsx("h4",{className:"text-lg font-semibold "+(i?"text-brand-accent-dark":"text-brand-primary-dark"),children:e}),n.jsx("p",{className:"text-brand-neutral-700 text-sm sm:text-base",children:a})]}),ue=[{time:"08:30-08:45",event:"Opening remarks, goals, challenge overview",icon:p,type:"general"},{time:"08:45-09:45",event:"Oral presentations (Session 1)",icon:k,type:"presentation"},{time:"09:45-10:15",event:"Keynote 1: Prof. Richard Bowden",icon:S,type:"keynote"},{time:"10:15-11:15",event:"Oral presentations (Session 2)",icon:k,type:"presentation"},{time:"11:15-11:30",event:"Coffee Break & Networking",icon:A,type:"break"},{time:"11:30-12:00",event:"Keynote 2: Dr. Oscar Koller",icon:S,type:"keynote"},{time:"12:00-13:00",event:"Oral presentations (Session 3)",icon:k,type:"presentation"},{time:"13:00-14:00",event:"Lunch Break",icon:A,type:"break"},{time:"14:00-15:00",event:"Oral presentations (Session 4)",icon:k,type:"presentation"},{time:"15:00-15:30",event:"Keynote 3: Dr. Leon Sigal",icon:S,type:"keynote"},{time:"15:30-17:30",event:"Poster Session & Demos",icon:b,type:"poster"},{time:"17:30-18:00",event:"Panel Discussion: Dataset Curation & Future Directions",icon:I,type:"panel"},{time:"18:00-18:15",event:"Awards and Closing Remarks",icon:g,type:"general"}],ge=[{name:"Prof. Richard Bowden",affiliation:"University of Surrey, UK",imgSrc:ae,bio:"Richard Bowden is Professor of Computer Vision and Machine Learning at the University of Surrey where he leads the Cognitive Vision Group within CVSSP and is Associate Dean for postgraduate research within his faculty. His research centres on the use of computer vision to locate, track, understand and learn from humans.",link:"https://scholar.google.com/citations?user=mvvgDvcAAAAJ"},{name:"Dr. Oscar Koller",affiliation:"Microsoft Inc., USA",imgSrc:te,bio:"Oscar Koller is an applied scientist in Microsoft's Speech and Language group. His research interests span many topics across speech recognition, sign language translation, sign language production, and computer vision in general.",title:"Delivering Sign Language AI at Scale: From Synthetic Data to Real-World Use",abstract:"In this keynote, we share our journey toward making sign language technologies a core part of Microsoft’s accessibility efforts—particularly in enhancing communication experiences for Deaf and sign language users in Microsoft Teams. We highlight the transformative role of synthetic data in overcoming the scarcity of annotated sign language datasets, enabling scalable, inclusive, and diverse training resources. By leveraging time-synchronized multi-view capture, precise registration, and rendering pipelines, we generate richly labeled synthetic data across varied identities and environments. We advocate for community-driven multi-view data collection and emphasize that zero-shot evaluation—without fine-tuning—is the true benchmark for real-world deployment. This talk outlines our key learnings and invites collaboration to advance sign language technology for all.",link:"https://scholar.google.com/citations?hl=it&user=vZrN9OgAAAAJ"},{name:"Dr. Leonid Sigal",affiliation:"University of British Columbia, Canada",imgSrc:ne,bio:"Prof. Leonid Sigal is a Professor at the University of British Columbia (UBC). He was appointed CIFAR AI Chair at the Vector Institute in 2019 and an NSERC Tier 2 Canada Research Chair in Computer Vision and Machine Learning in 2018. Prior to this, he was a Senior Research Scientist, and a group lead, at Disney Research. He completed his Ph.D at Brown University in 2008; received his B.Sc. degrees in Computer Science and Mathematics from Boston University in 1999, his M.A. from Boston University in 1999, and his M.S. from Brown University in 2003. Leonid’s research interests lie in the areas of computer vision, machine learning, and computer graphics; with the emphasis on approaches for visual and multi-modal representation learning, recognition, understanding and generative modeling. He has won a number of research awards, including Killam Accelerator Fellowship in 2021 and has published over 100 papers in venues such as CVPR, ICCV, ECCV, NeurIPS, ICLR, and Siggraph.",link:"https://scholar.google.com/citations?user=P2mG6rcAAAAJ&hl=en"},{name:"Dr. Abraham Glasser",affiliation:"Gallaudet University, USA",imgSrc:se,bio:"Dr. Abraham Glasser is a faculty member in the Accessible Human-Centered Computing program at Gallaudet University, and there he is also co-director of the Rehabilitation Engineering Research Center on Technology for the Deaf and Hard of Hearing (DHH RERC). He and his students conduct Human Computer Interaction (HCI) research involving AI, immersive technologies, and accessible computing for Deaf and Hard of Hearing users. He is also a member of the Coalition for Sign Language Equity in Technology (CoSET) and has contributed to published resources supporting standards work, e.g. for AI-based interpreting. Overall, Dr. Glasser has published numerous works and delivered award-winning presentations at prestigious international venues, such as ACM, IEEE, and other events, including but not limited to AAATE, ASSETS, CHI, CSUN ATC, CUI, CVPR, DAC, EMNLP, GALA, ICED, LREC, TAPIA, TISLR, IEEE VR, VRST, W4A, XR ACCESS, and WFD events.",link:"https://scholar.google.com/citations?hl=en&user=z1fXN4AAAAAJ"}],pe=(e=0)=>({hidden:{opacity:0,y:30,scale:.95},visible:{opacity:1,y:0,scale:1,transition:{duration:.5,ease:"easeOut",delay:e}}}),xe=(e=0)=>({hidden:{opacity:0,x:-20},visible:{opacity:1,x:0,transition:{duration:.4,ease:"easeOut",delay:e}}}),be=[{title:"Paper Submission Platform",icon:R,content:"All papers must be submitted via the Microsoft CMT platform.",link:{text:"Submit via CMT",url:"https://cmt3.research.microsoft.com/User/Login?ReturnUrl=%2FMSLR2025"}},{title:"Formatting Your Manuscript",icon:x,items:["<strong>Page limit:</strong> 5 to 8 pages (including figures and tables). References may be on additional pages.","<strong>Formatting style:</strong> Follow the ICCV 2025 formatting guidelines.","<strong>File type:</strong> Submit as a single PDF file."],link:{text:"Download ICCV Author Kit",url:"https://media.eventhosts.cc/Conferences/ICCV2025/ICCV2025-Author-Kit-Feb.zip"}},{title:"Double-Blind Peer Review",icon:M,content:"We follow a <strong>double-blind review process</strong> with no rebuttal period. Submissions must be anonymized:",items:["Remove all author names and affiliations.","Anonymize any references, acknowledgements, code, and datasets.","Non-anonymized submissions may be desk-rejected."],footer:"Review criteria include relevance, novelty, technical merit, and clarity."},{title:"Presentation & Attendance",icon:b,items:["Accepted papers will be presented as either <strong>oral</strong> or <strong>poster presentations</strong>.","At least one author (or a designated representative) must attend the workshop <strong>in person</strong> to present the accepted paper.","By submitting a paper, authors also agree to potentially serve as reviewers for the workshop."]},{title:"Proceedings & Policy",icon:L,items:["Accepted papers will be published in the official <strong>ICCV 2025 workshop proceedings</strong>.","Failure to comply with submission and attendance requirements may result in removal from the program.","By submitting to MSLR 2025, authors affirm that the paper (or a substantially similar version) is <strong>not under review elsewhere</strong> and will not be submitted to another venue before the review process concludes."]}],fe=(e=0)=>({hidden:{opacity:0,y:20,scale:.98},visible:{opacity:1,y:0,scale:1,transition:{duration:.5,ease:"easeOut",delay:e}}}),ve=({guideline:e,index:a})=>{const t=e.icon;return n.jsxs(s.div,{className:"content-card h-full flex flex-col",variants:fe(.1*a),children:[n.jsxs("div",{className:"flex items-center mb-4",children:[n.jsx("span",{className:"p-3 bg-brand-primary/10 rounded-full mr-4 shadow-sm",children:n.jsx(t,{className:"w-6 h-6 text-brand-primary"})}),n.jsx("h3",{className:"text-xl lg:text-2xl font-semibold text-brand-primary-dark",children:e.title})]}),e.content&&n.jsx("p",{className:"text-brand-neutral-700 mb-3 leading-relaxed",dangerouslySetInnerHTML:{__html:e.content}}),e.items&&n.jsx("ul",{className:"space-y-2 text-brand-neutral-700 mb-3 leading-relaxed list-none",children:e.items.map(((e,a)=>n.jsxs("li",{className:"flex items-start",children:[n.jsx(u,{className:"w-5 h-5 mr-2 mt-1 text-brand-primary flex-shrink-0"}),n.jsx("span",{dangerouslySetInnerHTML:{__html:e}})]},a)))}),e.footer&&n.jsx("p",{className:"text-sm text-brand-neutral-600 mt-auto pt-3 border-t border-brand-neutral-200 leading-relaxed",children:e.footer}),e.link&&n.jsxs("a",{href:e.link.url,target:"_blank",rel:"noopener noreferrer",className:"btn btn-secondary text-sm mt-auto w-full sm:w-auto",children:[e.link.text.includes("Download")?n.jsx(D,{size:16,className:"mr-2"}):n.jsx(E,{size:16,className:"mr-2"}),e.link.text]})]})},ye=[{id:1,title:"Continuous Sign Language Recognition",icon:z,bgColor:"bg-brand-primary-light/10",borderColor:"border-brand-primary",textColor:"text-brand-primary-dark",accentColor:"text-brand-primary",image:"/ICCV-2025/assets/track1-D4-fuYYa.png",description:"Using the Isharah dataset, this track features around 14,000 videos across 1,000 unique sentences by 18 signers. Participants will be provided with pose modality data consisting of the upper body skeleton, 2D hand keypoints (both hands), face keypoints, and lips contour — totaling 86 keypoints per frame.\n\n",evaluation:"<strong>Evaluation:</strong> Submissions will be evaluated using <strong>Word Error Rate (WER)</strong>, which measures the edit distance (substitutions, deletions, insertions) between predicted and reference sentences. Lower WER indicates better performance.",subTasks:["<strong>Signer-Independent:</strong> Train your models on a subset of signers and evaluate on entirely unseen signers. This sub-task focuses on cross-signer generalization, which is critical for building scalable real-world continuous sign language recognition systems.","<strong>Unseen Sentences:</strong> Train on a subset of sentences and evaluate on structurally different, unseen sentences. This tests your model's ability to understand grammar, semantics, and sentence-level sign composition without prior exposure."],links:[{text:"Starter Kit",url:"https://github.com/gufranSabri/Pose86K-CSLR-Isharah",icon:P},{text:"Competition - Task 1 (CodaLab)",url:"https://codalab.lisn.upsaclay.fr/competitions/22899",icon:U},{text:"Competition - Task 2 (CodaLab)",url:"https://codalab.lisn.upsaclay.fr/competitions/22900",icon:U}],prizes:[{place:"1st Place",amount:"$1,000"},{place:"2nd Place",amount:"$750"},{place:"3rd Place",amount:"$500"}],sponsor:{name:"SharedTech",url:"https://www.sharedtech.com.sa/en"}},{id:2,title:"Isolated Sign Language Recognition",icon:T,bgColor:"bg-brand-accent-light/10",borderColor:"border-brand-accent",textColor:"text-brand-accent-dark",accentColor:"text-brand-accent",image:"/ICCV-2025/assets/track2-CsYkkGTY.png",description:"This track presents a sign language recognition task on our multimodal preliminary dataset, featuring RGB videos and 60-GHz radar range-Doppler maps, and including 126 Italian Sign Language gestures (100 medical terms + 26 letters) across 205 expert sessions.",evaluation:"<strong>Evaluation:</strong> Submissions will be evaluated using <strong>Top-1 Accuracy</strong>, which measures the percentage of correctly predicted gestures. Higher accuracy indicates better performance.",subTasks:[],links:[{text:"Competition (Kaggle)",url:"https://www.kaggle.com/competitions/iccv-mslr-2025-track-2",icon:U}],sponsor:null,prizes:[]}],we=(e=0)=>({hidden:{opacity:0,y:30},visible:{opacity:1,y:0,transition:{duration:.6,ease:"easeOut",delay:e}}}),je=({track:e,index:a})=>{const t=e.icon;return n.jsxs(s.div,{className:"rounded-xl shadow-2xl overflow-hidden flex flex-col lg:flex-row "+(e.id%2==0?"lg:flex-row-reverse":""),variants:we(.15*a),children:[n.jsxs("div",{className:"lg:w-2/5 xl:w-1/3 relative",children:[n.jsx("img",{src:e.image,alt:`Track ${e.id} visual`,className:"w-full h-64 lg:h-full object-cover"}),n.jsx("div",{className:"absolute inset-0 "+(1===e.id?"bg-brand-primary/30":"bg-brand-accent/30")})," "]}),n.jsxs("div",{className:`lg:w-3/5 xl:w-2/3 p-6 md:p-8 lg:p-10 ${e.bgColor} flex flex-col`,children:[n.jsxs("div",{className:"flex items-center mb-4",children:[n.jsx("span",{className:"p-3 rounded-full mr-4 shadow-sm "+("bg-brand-primary-light/10"===e.bgColor?"bg-brand-primary/20":"bg-brand-accent/20"),children:n.jsx(t,{className:`w-7 h-7 ${e.accentColor}`})}),n.jsx("h3",{className:`text-2xl lg:text-3xl font-bold ${e.textColor}`,children:e.title})]}),n.jsx("p",{className:"text-brand-neutral-700 mb-5 leading-relaxed text-sm sm:text-base flex-grow",children:e.description}),e.subTasks&&e.subTasks.length>0&&n.jsxs("div",{className:"mb-5",children:[n.jsx("h4",{className:`text-lg font-semibold mb-2 ${e.accentColor}`,children:"Sub-Tasks:"}),n.jsx("ul",{className:"space-y-1 text-brand-neutral-700 text-sm list-none pl-2",children:e.subTasks.map(((a,t)=>n.jsxs("li",{className:"flex items-start",children:[n.jsx(H,{className:`w-5 h-5 mr-2 mt-0.5 ${e.accentColor} flex-shrink-0`}),n.jsx("span",{dangerouslySetInnerHTML:{__html:a}})]},t)))})]}),n.jsx("p",{className:"text-brand-neutral-700 mb-5 leading-relaxed text-sm sm:text-base flex-grow",dangerouslySetInnerHTML:{__html:e.evaluation}}),n.jsx("div",{className:"flex flex-wrap gap-3 mb-6",children:e.links.map((e=>{const a=e.icon,t=e.text.toLowerCase().includes("competition")||e.text.toLowerCase().includes("task");return n.jsxs("a",{href:e.url,target:"_blank",rel:"noopener noreferrer",className:"btn btn-sm border !py-2 !px-4 text-xs sm:text-sm flex items-center\n                        "+(t?"bg-teal-700 text-white hover:bg-teal-800":"bg-teal-100 text-teal-900 hover:bg-teal-200"),children:[n.jsx(a,{size:16,className:"mr-1.5"})," ",e.text]},e.text)}))}),e.sponsor&&n.jsxs("p",{className:"text-sm text-brand-neutral-600 mb-1",children:["🤝 Sponsor: ",n.jsx("a",{href:e.sponsor.url,target:"_blank",rel:"noopener noreferrer",className:"font-semibold hover:underline",style:{color:e.accentColor.replace("text-","")},children:e.sponsor.name})]}),e.prizes&&e.prizes.length>0&&n.jsxs("div",{children:[n.jsxs("p",{className:`text-sm font-semibold ${e.accentColor} mb-1 flex items-center`,children:[n.jsx(V,{size:16,className:"mr-1.5"}),"Prizes:"]}),n.jsx("ul",{className:"text-xs sm:text-sm text-brand-neutral-600 list-disc list-inside space-y-0.5",children:e.prizes.map((e=>n.jsxs("li",{children:[n.jsxs("strong",{children:[e.place,":"]})," ",e.amount]},e.place)))})]})]})]})},Ce={chairs:[{name:"Dr. Hamzah Luqman",affiliation:"King Fahd University of Petroleum and Minerals, KSA",imgSrc:"/ICCV-2025/assets/HamzahLuqman-Do2YTJTx.jpeg",link:"https://scholar.google.com/citations?user=JgGFu2QAAAAJ&hl=en"},{name:"Eng. Raffaele Mineo",affiliation:"University of Catania, Italy",imgSrc:"/ICCV-2025/assets/raffaele-CzaArnAF.jpeg",link:"https://scholar.google.com/citations?hl=en&user=nYSplWUAAAAJ"},{name:"Dr. Maad Alowaifeer",affiliation:"King Fahd University of Petroleum & Minerals, KSA",imgSrc:"/ICCV-2025/assets/maad-B6S51BNQ.jpg",link:"https://scholar.google.com/citations?hl=en&user=dLjEuacAAAAJ"},{name:"Dr. Simone Palazzo",affiliation:"University of Catania, Italy",imgSrc:"/ICCV-2025/assets/simone-SkA2oKps.png",link:"https://scholar.google.com/citations?hl=en&user=yJr6TqAAAAAJ"}],workshopOrganizers:["Dr. Motaz Alfarraj — King Fahd University of Petroleum & Minerals (KFUPM), KSA","Dr. Mufti Mahmud — King Fahd University of Petroleum & Minerals, KSA","Eng. Amelia Sorrenti — University of Catania, Italy","Dr. Federica Proietto Salanitri — University of Catania, Italy","Dr. Giovanni Bellitto — University of Catania, Italy","Dr. Concetto Spampinato — University of Catania, Italy","Dr. Silvio Giancola — King Abdullah University of Science and Technology, KSA","Dr. Muhammad Haris Khan — Mohamed Bin Zayed University of AI, UAE","Dr. Moi Hoon Yap — Manchester Metropolitan University, UK"],challengeOrganizers:["Ahmed Abul Hasanaath — King Fahd University of Petroleum & Minerals, KSA","Murtadha Aljubran — Mohamed Bin Zayed University of Artificial Intelligence, UAE","Sarah Alyami — King Fahd University of Petroleum & Minerals, KSA","Dr. Egidio Ragonese — University of Catania, Italy","Dr. Gaia Caligiore - University of Modena and Reggio Emilia, Italy","Dr. Sabina Fontana - University of Catania, Italy","Dr. Senya Polikovsky — Max Planck Institute for Intelligent Systems, Tübingen, Germany","Dr. Sevgi Z. Gurbuz — North Carolina State University, USA","Eng. Kamrul Islam — North Carolina State University, USA"],contact:[{name:"Eng. Raffaele Mineo",email:"raffaele.mineo[at]unict.it"},{name:"Dr. Hamzah Luqman",email:"hluqman[at]kfupm.edu.sa"}]},Ne=(e=0)=>({hidden:{opacity:0,y:20,scale:.95},visible:{opacity:1,y:0,scale:1,transition:{duration:.5,ease:"easeOut",delay:e}}}),ke=(e=0)=>({hidden:{opacity:0,x:-15},visible:{opacity:1,x:0,transition:{duration:.4,ease:"easeOut",delay:e}}}),Se=({person:e,delay:a})=>n.jsxs(s.div,{className:"bg-white p-6 rounded-xl shadow-lg text-center group transform transition-all duration-300 hover:shadow-2xl hover:scale-105",variants:Ne(a),children:[n.jsx("img",{src:e.imgSrc,alt:e.name,className:"w-28 h-28 md:w-32 md:h-32 rounded-full object-cover mx-auto mb-4 border-4 border-brand-accent/30 group-hover:border-brand-accent transition-colors duration-300 shadow-md"}),n.jsx("h4",{className:"text-lg font-semibold text-brand-primary-dark mb-0.5",children:n.jsx("a",{href:e.link,target:"_blank",children:e.name})}),n.jsx("p",{className:"text-brand-neutral-600 text-xs sm:text-sm",children:e.affiliation})]}),Ae=({title:e,items:a,Icon:t,delay:i})=>n.jsxs(s.div,{className:"content-card h-full",variants:Ne(i),children:[n.jsxs("div",{className:"flex items-center mb-5",children:[n.jsx("span",{className:"p-3 bg-brand-accent/10 rounded-full mr-4 shadow-sm",children:n.jsx(t,{className:"w-6 h-6 text-brand-accent"})}),n.jsx("h3",{className:"text-xl lg:text-2xl font-semibold text-brand-accent-dark",children:e})]}),n.jsx("ul",{className:"space-y-2.5 text-brand-neutral-700",children:a.map(((e,a)=>n.jsxs(s.li,{className:"flex items-start text-sm sm:text-base",variants:ke(.05*a),children:[n.jsx(F,{className:"w-5 h-5 mr-2.5 mt-0.5 text-brand-accent-light flex-shrink-0"}),n.jsx("span",{children:e})]},a)))})]}),Ie=[{id:"home",name:"Home",component:()=>n.jsxs(n.Fragment,{children:[n.jsx(ee,{id:"home-overview-internal",title:"Welcome to MSLR 2025",subtitle:"",bgColor:"bg-white",contentMaxWidth:"max-w-4xl",children:n.jsx("div",{className:"space-y-6 text-lg text-brand-neutral-700 leading-relaxed",children:ie.overview.map(((e,a)=>n.jsxs(s.p,{variants:oe,children:[" ",e]},a)))})}),n.jsxs(ee,{id:"home-cfp-internal",title:"Call for Papers",subtitle:"Contribute Your Research",bgColor:"bg-brand-neutral-100",children:[n.jsx(s.p,{className:"max-w-3xl mx-auto text-center text-lg text-brand-neutral-700 mb-12 leading-relaxed",variants:oe,children:ie.callForPapers.intro}),n.jsx("div",{className:"grid md:grid-cols-2 gap-8 lg:gap-10",children:ie.callForPapers.categories.map(((e,a)=>n.jsxs(s.div,{className:"content-card transform hover:scale-[1.03]",variants:le(.1*a),children:[n.jsxs("div",{className:"flex items-center mb-4",children:[n.jsx("span",{className:"p-3 bg-brand-accent/10 rounded-full mr-4 shadow-sm",children:e.icon}),n.jsx("h3",{className:"text-xl lg:text-2xl font-semibold text-brand-primary-dark",children:e.title})]}),n.jsx("ul",{className:"space-y-3 text-brand-neutral-700 text-sm sm:text-base",children:e.items.map(((e,a)=>n.jsxs(s.li,{className:"flex",variants:oe,children:[n.jsx(u,{className:"w-5 h-5 mr-2 mt-1 text-brand-accent flex-shrink-0"}),n.jsx("span",{children:e})]},a)))})]},e.title)))}),n.jsxs(s.p,{className:"mt-12 text-center text-lg text-brand-neutral-700 max-w-3xl mx-auto leading-relaxed",variants:oe,children:[ie.callForPapers.outro," See the ",n.jsx("button",{onClick:e=>{e.preventDefault();const a=document.getElementById("submission"),t=document.querySelector("header"),n=t?t.offsetHeight:80;if(a){const e=a.getBoundingClientRect().top+window.pageYOffset-n;window.scrollTo({top:e,behavior:"smooth"})}},className:"btn-link",children:"Submission Guidelines"})," for more details."]})]}),n.jsx(ee,{id:"program-speakers-internal",title:"Invited Speakers",subtitle:"Learn from the Leaders",bgColor:"bg-white",children:n.jsx("div",{className:"grid md:grid-cols-1 lg:grid-cols-3 gap-8 lg:gap-10",children:re.map(((e,a)=>n.jsxs(s.div,{className:"content-card flex flex-col text-center transform hover:scale-[1.02]",variants:le(.1*a),children:[n.jsx("img",{src:e.imgSrc,alt:e.name,className:"w-32 h-32 md:w-36 md:h-36 rounded-full object-cover mx-auto mb-5 border-4 border-brand-accent/40 group-hover:border-brand-accent transition-colors duration-300 shadow-md"}),n.jsx("h3",{className:"text-xl lg:text-2xl font-semibold text-brand-primary-dark mb-1",children:e.name}),n.jsx("p",{className:"text-brand-neutral-600 text-sm mb-3",children:e.affiliation}),n.jsx("p",{className:"text-sm text-brand-neutral-700 leading-relaxed flex-grow mb-4 px-2",children:e.bio}),e.link&&n.jsxs("a",{href:e.link,target:"_blank",rel:"noopener noreferrer",className:"btn-link text-sm inline-flex items-center justify-center mt-auto",children:["View Profile ",n.jsx(h,{size:14,className:"ml-1.5"})]})]},e.name)))})})]}),hasHero:!0},{id:"schedule",name:"Schedule",component:()=>n.jsxs(ee,{id:"schedule-internal",title:"Important Dates",subtitle:"",bgColor:"bg-brand-neutral-50",children:[n.jsxs("div",{className:"grid md:grid-cols-2 gap-12 lg:gap-16",children:[n.jsxs(s.div,{className:"content-card",variants:de(0),children:[n.jsxs("div",{className:"flex items-center mb-6",children:[n.jsx("span",{className:"p-3 bg-brand-primary/10 rounded-full mr-4 shadow-sm",children:n.jsx(f,{className:"w-8 h-8 text-brand-primary"})}),n.jsx("h3",{className:"text-2xl lg:text-3xl font-semibold text-brand-primary-dark",children:"Workshop Deadlines"})]}),n.jsx("ul",{className:"space-y-4",children:ce.workshop.map(((e,a)=>n.jsx(he,{date:e.date,event:e.event,Icon:e.icon,highlight:e.highlight,delay:.1*a},`ws-${a}`)))})]}),n.jsxs(s.div,{className:"content-card",variants:de(.15),children:[n.jsxs("div",{className:"flex items-center mb-6",children:[n.jsx("span",{className:"p-3 bg-brand-accent/10 rounded-full mr-4 shadow-sm",children:n.jsx(g,{className:"w-8 h-8 text-brand-accent"})}),n.jsx("h3",{className:"text-2xl lg:text-3xl font-semibold text-brand-accent-dark",children:"Challenge Deadline"})]}),n.jsx("ul",{className:"space-y-4",children:ce.challenge.map(((e,a)=>n.jsx(he,{date:e.date,event:e.event,Icon:e.icon,highlight:e.highlight,delay:.1*a},`ch-${a}`)))})]})]}),n.jsxs(s.p,{className:"mt-12 text-center text-brand-neutral-600 italic flex items-center justify-center",initial:{opacity:0},animate:{opacity:1},transition:{delay:.5},children:[n.jsx(N,{size:18,className:"mr-2 text-brand-neutral-500"})," All deadlines are at 23:59 Anywhere on Earth (AoE)."]})]})},{id:"program",name:"Program",component:()=>n.jsxs(n.Fragment,{children:[n.jsx(ee,{id:"program-schedule-internal",title:"Workshop Program",subtitle:"Day at a Glance",bgColor:"bg-brand-neutral-100",children:n.jsx(s.div,{className:"bg-white shadow-xl rounded-xl overflow-hidden",variants:pe(0),children:n.jsx("div",{className:"divide-y divide-brand-neutral-200",children:ue.map(((e,a)=>{const t=e.icon,i=(e=>{switch(e){case"keynote":return"bg-brand-accent/10 text-brand-accent-dark border-brand-accent";case"presentation":return"bg-brand-primary/10 text-brand-primary-dark border-brand-primary";case"break":return"bg-yellow-400/10 text-yellow-700 border-yellow-500";case"poster":return"bg-purple-500/10 text-purple-700 border-purple-600";case"panel":return"bg-indigo-500/10 text-indigo-700 border-indigo-600";default:return"bg-gray-400/10 text-gray-700 border-gray-500"}})(e.type);return n.jsxs(s.div,{className:"p-4 sm:p-6 flex flex-col sm:flex-row items-start sm:items-center space-y-2 sm:space-y-0 sm:space-x-6 hover:bg-brand-neutral-50 transition-colors duration-200 "+(a%2==0?"":"bg-brand-neutral-50/50"),variants:xe(.05*a),children:[n.jsxs("div",{className:"flex items-center shrink-0 w-full sm:w-auto",children:[n.jsx("span",{className:`p-2 rounded-full mr-3 ${i.split(" ")[0]}`,children:n.jsx(t,{size:20,className:`${i.split(" ")[1]}`})}),n.jsx("span",{className:"font-sharetech text-sm sm:text-base text-brand-neutral-700 w-28 sm:w-32",children:e.time})]}),n.jsx("p",{className:"text-sm sm:text-base text-brand-neutral-800 flex-grow",children:e.event})]},a)}))})})}),n.jsx(ee,{id:"program-speakers-internal",title:"Invited Speakers",subtitle:"Learn from the Leaders",bgColor:"bg-white",children:n.jsx("div",{className:"grid md:grid-cols-1 lg:grid-cols-3 gap-8 lg:gap-10",children:ge.map(((e,a)=>n.jsxs(s.div,{className:"content-card flex flex-col text-center transform hover:scale-[1.02]",variants:pe(.1*a),children:[n.jsx("img",{src:e.imgSrc,alt:e.name,className:"w-32 h-32 md:w-36 md:h-36 rounded-full object-cover mx-auto mb-5 border-4 border-brand-accent/40 group-hover:border-brand-accent transition-colors duration-300 shadow-md"}),n.jsx("h3",{className:"text-xl lg:text-2xl font-semibold text-brand-primary-dark mb-1",children:e.name}),n.jsx("p",{className:"text-brand-neutral-600 text-sm mb-3",children:e.affiliation}),n.jsx("p",{className:"text-sm text-brand-neutral-700 leading-relaxed flex-grow mb-4 px-2",children:e.bio}),e.title&&n.jsx("h4",{className:"text-lg font-semibold text-brand-primary-dark mt-2 px-2",children:e.title}),e.abstract&&n.jsx("p",{className:"text-sm text-brand-neutral-700 leading-relaxed mb-4 px-2",children:e.abstract}),e.link&&n.jsxs("a",{href:e.link,target:"_blank",rel:"noopener noreferrer",className:"btn-link text-sm inline-flex items-center justify-center mt-auto",children:["View Profile ",n.jsx(h,{size:14,className:"ml-1.5"})]})]},e.name)))})})]})},{id:"submission",name:"Submissions",component:()=>n.jsxs(ee,{id:"submission-internal",title:"Submission Guidelines",subtitle:"Share Your Work",bgColor:"bg-brand-neutral-100",children:[n.jsx("div",{className:"grid md:grid-cols-2 lg:grid-cols-3 gap-8",children:be.map(((e,a)=>n.jsx(ve,{guideline:e,index:a},e.title)))}),n.jsx(s.div,{className:"mt-12 text-center",initial:{opacity:0},animate:{opacity:1},transition:{delay:.1*be.length+.2},children:n.jsxs("a",{href:"https://cmt3.research.microsoft.com/User/Login?ReturnUrl=%2FMSLR2025",target:"_blank",rel:"noopener noreferrer",className:"btn btn-primary btn-lg text-lg px-8 py-4",children:[n.jsx(R,{size:20,className:"mr-2.5"})," Go to CMT Submission Portal"]})}),n.jsx("div",{className:"mt-8 text-center text-sm text-brand-neutral-600",children:"The Microsoft CMT service (https://cmt3.research.microsoft.com/) was used for managing the peer-reviewing process for this conference. This service was provided for free by Microsoft and they bore all expenses, including costs for Azure cloud services as well as for software development and support."})]})},{id:"challenge",name:"Challenge",component:()=>n.jsxs(ee,{id:"challenge-internal",title:"SignEval 2025: The First Multimodal Sign Language Recognition Challenge",subtitle:"Push the Boundaries",bgColor:"bg-white",children:[n.jsx(s.p,{className:"max-w-3xl mx-auto text-center text-lg text-brand-neutral-700 mb-12 md:mb-16 leading-relaxed",initial:{opacity:0,y:10},animate:{opacity:1,y:0},transition:{delay:.2},children:"The MSLR Challenge comprises two exciting tracks. Whether you're interested in continuous sequences or isolated gestures, there's a challenge waiting for you."}),n.jsx("div",{className:"space-y-12 md:space-y-16",children:ye.map(((e,a)=>n.jsx(je,{track:e,index:a},e.id)))})]})},{id:"organizers",name:"Organizers",component:()=>n.jsxs(n.Fragment,{children:[n.jsx(ee,{id:"organizers-chairs-internal",title:"Workshop Chairs",subtitle:"Meet the Leadership",bgColor:"bg-brand-neutral-100",children:n.jsx("div",{className:"grid sm:grid-cols-2 lg:grid-cols-4 gap-6 md:gap-8",children:Ce.chairs.map(((e,a)=>n.jsx(Se,{person:e,delay:.1*a},e.name)))})}),n.jsx(ee,{id:"organizers-teams-internal",title:"Our Teams",subtitle:"Dedicated Committees",bgColor:"bg-white",children:n.jsxs("div",{className:"grid md:grid-cols-1 lg:grid-cols-2 gap-8 md:gap-12",children:[n.jsx(Ae,{title:"Workshop Organizers",items:Ce.workshopOrganizers,Icon:b,delay:0}),n.jsx(Ae,{title:"Challenge Organizers",items:Ce.challengeOrganizers,Icon:g,delay:.1})," "]})}),n.jsx(ee,{id:"organizers-contact-internal",title:"Contact Us",subtitle:"Get in Touch",bgColor:"bg-brand-neutral-800",titleClassName:"text-white",children:n.jsxs(s.div,{className:"max-w-2xl mx-auto bg-white p-8 md:p-10 rounded-xl shadow-2xl text-center",variants:Ne(0),children:[n.jsx(O,{className:"w-12 h-12 text-brand-accent mx-auto mb-4"}),n.jsx("h3",{className:"text-2xl lg:text-3xl font-semibold text-brand-primary-dark mb-3",children:"Questions or Clarifications?"}),n.jsx("p",{className:"text-brand-neutral-700 mb-6 leading-relaxed",children:"Feel free to reach out to our organizing chairs for any inquiries regarding the workshop."}),n.jsx("div",{className:"space-y-3",children:Ce.contact.map((e=>n.jsxs("div",{children:[n.jsxs("p",{className:"font-semibold text-brand-neutral-800",children:[e.name,":"]}),n.jsx("a",{href:`mailto:${e.email.replace("[at]","@")}`,className:"text-brand-accent hover:underline",children:e.email})]},e.name)))}),n.jsxs("div",{className:"mt-8 pt-6 border-t border-brand-neutral-200 flex items-center justify-center text-brand-neutral-600",children:[n.jsx(B,{size:20,className:"mr-2 text-brand-primary"}),n.jsx("span",{children:"IEEE/CVF ICCV 2025, Honolulu, Hawaii, USA"})]})]})})]})}];function Re(){const[e,a]=t.useState("hero"),s=t.useRef({}),i=t.useRef(null),r=t.useRef(null);s.current.hero=t.useRef(null),Ie.forEach((e=>{s.current[e.id]=t.useRef(null)}));const o=t.useCallback((e=>{var a;const t=null==(a=s.current[e])?void 0:a.current;if(!t)return;const n=i.current?i.current.offsetHeight:80,r=t.getBoundingClientRect().top+window.scrollY-n;window.scrollTo({top:r,behavior:"smooth"})}),[]);return t.useEffect((()=>{const e=i.current?i.current.offsetHeight:80,t={root:null,rootMargin:`-${e+10}px 0px -${window.innerHeight-e-150}px 0px`,threshold:.01};return r.current&&r.current.disconnect(),r.current=new IntersectionObserver((e=>{const t=e.filter((e=>e.isIntersecting));if(t.length>0){const e=t.reduce(((e,a)=>e.intersectionRatio>a.intersectionRatio?e:a));a(e.target.id)}}),t),Object.values(s.current).forEach((e=>{e.current&&r.current.observe(e.current)})),()=>{r.current&&r.current.disconnect()}}),[]),n.jsxs("div",{className:"flex flex-col min-h-screen bg-brand-neutral-50",children:[n.jsx(W,{ref:i,navLinks:Ie,activeSection:e,onNavClick:o}),n.jsxs("main",{className:"flex-grow",children:[n.jsx("div",{id:"hero",ref:s.current.hero,children:n.jsx(Z,{})}),Ie.map((e=>{const a=e.component;return n.jsx("div",{id:e.id,ref:s.current[e.id],children:n.jsx(a,{})},e.id)}))]}),n.jsx(Q,{})]})}$.createRoot(document.getElementById("root")).render(n.jsx(r.StrictMode,{children:n.jsx(Re,{})}));
